import{_ as a,o as s,c as i,aA as t}from"./chunks/framework.BjnFN11a.js";const u=JSON.parse('{"title":"Benchmark Methodology","description":"","frontmatter":{},"headers":[],"relativePath":"manual/benchmarks.md","filePath":"manual/benchmarks.md","lastUpdated":null}'),n={name:"manual/benchmarks.md"};function o(r,e,p,l,h,c){return s(),i("div",null,[...e[0]||(e[0]=[t(`<h1 id="Benchmark-Methodology" tabindex="-1">Benchmark Methodology <a class="header-anchor" href="#Benchmark-Methodology" aria-label="Permalink to &quot;Benchmark Methodology {#Benchmark-Methodology}&quot;">​</a></h1><p>This page documents how QuantNova performance numbers are produced and how to reproduce them.</p><h2 id="Principles" tabindex="-1">Principles <a class="header-anchor" href="#Principles" aria-label="Permalink to &quot;Principles {#Principles}&quot;">​</a></h2><ul><li><p><strong>Warmup first:</strong> all benchmarks run warmup iterations to remove JIT compilation effects.</p></li><li><p><strong>Median reporting:</strong> we report the <strong>median</strong> runtime across repeated runs.</p></li><li><p><strong>Fixed inputs:</strong> parameters and random seeds are fixed in each benchmark script.</p></li><li><p><strong>Single-process by default:</strong> scripts do not enable explicit multithreading or GPU backends.</p></li></ul><h2 id="Benchmark-Suites" tabindex="-1">Benchmark Suites <a class="header-anchor" href="#Benchmark-Suites" aria-label="Permalink to &quot;Benchmark Suites {#Benchmark-Suites}&quot;">​</a></h2><h3 id="1-QuantNova-Comprehensive-Suite-Julia" tabindex="-1">1) QuantNova Comprehensive Suite (Julia) <a class="header-anchor" href="#1-QuantNova-Comprehensive-Suite-Julia" aria-label="Permalink to &quot;1) QuantNova Comprehensive Suite (Julia) {#1-QuantNova-Comprehensive-Suite-Julia}&quot;">​</a></h3><p><strong>Script:</strong> <code>benchmarks/comparison/comprehensive_benchmark.jl</code></p><p><strong>Timing method:</strong> <code>@elapsed</code> in Julia, times converted to microseconds, median reported.</p><p><strong>Key parameters (fixed in the script):</strong></p><ul><li><p><strong>European Black‑Scholes:</strong> <code>S=100</code>, <code>K=100</code>, <code>T=1</code>, <code>r=0.05</code>, <code>σ=0.2</code> Runs: 10,000 (warmup: 1,000)</p></li><li><p><strong>American binomial:</strong> 100 steps Runs: 500 (warmup: 50)</p></li><li><p><strong>SABR implied vol:</strong> <code>F=100</code>, <code>K=100</code>, <code>T=1</code>, <code>α=0.2</code>, <code>β=0.5</code>, <code>ρ=-0.3</code>, <code>ν=0.4</code> Runs: 10,000 (warmup: 1,000)</p></li><li><p><strong>Batch pricing:</strong> 1,000 options, <code>K∈[80,120]</code>, <code>T∈[0.1,2.0]</code>, <code>σ∈[0.1,0.5]</code> <code>Random.seed!(42)</code> Runs: 100 (warmup: 10)</p></li><li><p><strong>Greeks (AD):</strong> <code>compute_greeks</code> on a European option Runs: 1,000 (warmup: 100)</p></li><li><p><strong>Monte Carlo:</strong> 10,000 paths, 50 steps for European and Asian Runs: 20 (warmup: 2)</p></li><li><p><strong>American LSM:</strong> 10,000 paths, 50 steps Runs: 10 (warmup: 2)</p></li><li><p><strong>Backtesting / Factor / Statistics:</strong> synthetic data, <code>Random.seed!(42)</code> 5 years of daily data (252 * 5)</p></li></ul><p><strong>Run:</strong></p><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">julia</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> --project=.</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> benchmarks/comparison/comprehensive_benchmark.jl</span></span></code></pre></div><h3 id="2-QuantLib-C-Comparison-Direct-C" tabindex="-1">2) QuantLib C++ Comparison (Direct C++) <a class="header-anchor" href="#2-QuantLib-C-Comparison-Direct-C" aria-label="Permalink to &quot;2) QuantLib C++ Comparison (Direct C++) {#2-QuantLib-C-Comparison-Direct-C}&quot;">​</a></h3><p><strong>Scripts:</strong></p><ul><li><p><code>benchmarks/comparison/quantlib_benchmark.cpp</code></p></li><li><p><code>benchmarks/comparison/quantlib_benchmark_extended.cpp</code></p></li></ul><p><strong>Timing method:</strong> <code>std::chrono</code> in C++, median reported.</p><p><strong>Parameters:</strong> Same as the Julia benchmarks (e.g., <code>S=100</code>, <code>K=100</code>, <code>T=1</code>, <code>r=0.05</code>, <code>σ=0.2</code>).</p><p><strong>Compile &amp; run (from script comments):</strong></p><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">clang++</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -std=c++17</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -O3</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -I</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&lt;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">HOME</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&gt;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">/dev/QuantLib</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -L</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&lt;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">HOME</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&gt;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">/dev/QuantLib/build/ql</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> \\</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  -lQuantLib</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -o</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> quantlib_benchmark</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> benchmarks/comparison/quantlib_benchmark.cpp</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">DYLD_LIBRARY_PATH</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=&lt;</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">HOME</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&gt;</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">/dev/QuantLib/build/ql</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> ./quantlib_benchmark</span></span></code></pre></div><h3 id="3-QuantLib-Comparison-via-PyCall-Julia" tabindex="-1">3) QuantLib Comparison via PyCall (Julia) <a class="header-anchor" href="#3-QuantLib-Comparison-via-PyCall-Julia" aria-label="Permalink to &quot;3) QuantLib Comparison via PyCall (Julia) {#3-QuantLib-Comparison-via-PyCall-Julia}&quot;">​</a></h3><p><strong>Script:</strong> <code>benchmarks/comparison/quantlib_comparison.jl</code></p><p>This uses <strong>QuantLib’s Python bindings</strong> through <code>PyCall</code>. It verifies correctness first and then benchmarks.</p><p><strong>Notes:</strong></p><ul><li><strong>Theta units differ:</strong> QuantLib returns per‑day theta; QuantNova reports per‑year. The script converts QuantNova theta to per‑day for a fair comparison.</li></ul><p><strong>Run:</strong></p><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">julia</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> --project=.</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> benchmarks/comparison/quantlib_comparison.jl</span></span></code></pre></div><h3 id="4-Python-Baselines-pandas-/-statsmodels-/-vectorbt" tabindex="-1">4) Python Baselines (pandas / statsmodels / vectorbt) <a class="header-anchor" href="#4-Python-Baselines-pandas-/-statsmodels-/-vectorbt" aria-label="Permalink to &quot;4) Python Baselines (pandas / statsmodels / vectorbt) {#4-Python-Baselines-pandas-/-statsmodels-/-vectorbt}&quot;">​</a></h3><p><strong>Script:</strong> <code>benchmarks/comparison/python_benchmark.py</code></p><p><strong>Timing method:</strong> <code>time.perf_counter</code>, median reported.</p><p><strong>Dependencies:</strong> <code>numpy</code>, <code>pandas</code>, <code>scipy</code>, <code>statsmodels</code>, optional <code>vectorbt</code>.</p><p><strong>Run:</strong></p><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">python</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> benchmarks/comparison/python_benchmark.py</span></span></code></pre></div><h2 id="Reproducibility-Tips" tabindex="-1">Reproducibility Tips <a class="header-anchor" href="#Reproducibility-Tips" aria-label="Permalink to &quot;Reproducibility Tips {#Reproducibility-Tips}&quot;">​</a></h2><ul><li><p>Run on an idle machine when possible.</p></li><li><p>Report <strong>CPU model, OS, and Julia version</strong> with your results.</p></li><li><p>If you change <code>JULIA_NUM_THREADS</code> or enable GPU backends, note it explicitly.</p></li></ul><h2 id="Where-Results-Appear" tabindex="-1">Where Results Appear <a class="header-anchor" href="#Where-Results-Appear" aria-label="Permalink to &quot;Where Results Appear {#Where-Results-Appear}&quot;">​</a></h2><p>Performance summaries in the README and docs are derived from these scripts and should be updated whenever benchmarks are re‑run.</p>`,36)])])}const k=a(n,[["render",o]]);export{u as __pageData,k as default};
